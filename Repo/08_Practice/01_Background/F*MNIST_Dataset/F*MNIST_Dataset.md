This is a data preparation pipeline I made for the F-MNIST dataset. The work came about from collaborating with [Meg Benson](https://meganbenson.me/) and [Yasmin Morgan](https://yasminmorgan.com/). In conversations we wanted to question how we could make a chaotic  dataset of hand written letters to form our own dataset and generate a local dataset of fonts with our intentions and contexts entangled into them. This data set explored how we could disorient the standardised norms of AI datasets such as the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) (Modified National Institute of Standards and Technology) by trying to de-isolate and un-normalize their indexes and figures by situating them, bringing in their backgrounds and entangling them together. We also left space within the inputs for people to add their own symbols and data outside of the limits of the Latin alphabet. 

![](media/fmnist_dataset.gif)

This work did this technically by scanning in hand written samples on paper and splitting them into the different segments. In the interface for doing this it also made room for people to add intentions for their data as well as their name and bits about their background. I wrote this in python and used a rdflib to write a custom linked open data (LOD) dataset that entangled the images to this data through semantic triples. This was informed by a workshopI attended called Fermenting Data[^1] by Magdalena Ty≈ºlik-Carver, Lozana Rossenova and Lukas Fuchsgruber, where they made room within the semantic triples of LOD to form and unfold different relations in data.

This project didn't make it past being a pipeline mainly due to two frictions. The first that at this point I had not focused on a technical practice that was very shareable or accessible to my collaborators, and so it lost momentum. The second was that this would have been best served online, as this would make room for the dataset to unfold as it was added to, but none of us had those technical skills and so it stayed scanned/paper base. In this reflection though the work did make room for me to question in collaboration the ways we could imagine and store data in more nuanced and situated ways to try and trouble the ways AI and ML are approached.

https://github.com/CorsicAr/DataProccessing